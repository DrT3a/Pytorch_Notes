{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tensors.\n",
    "\n",
    "They are the data structures we use when programming with neural networks.\n",
    "The first actions we take are data preprocessing routines that convert our data to tensors that will be fed into our neural network.\n",
    "Tensors in Pytorch are represented using the **torch.Tensor** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a torch tensor using a class constructor:\n",
    "t = torch.Tensor()\n",
    "print(t)\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the basic tensor attributes we discussed earlier, there are specific pytorch tensor attributes that deal with pytorches implementations.\n",
    "These are:  \n",
    "- Datatype\n",
    "- Device\n",
    "- Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datatype\n",
    "The datatype (.float32) specifies the *type* of data that is stored within the tensor.Tensors contain uniform (of the same type) numerical data with one of these types: \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "![image_a](Img\\data_types.JPG) \n",
    "\n",
    "</div>\n",
    "\n",
    "> Tensors have a CPU and a GPU version.   \n",
    "> **Tensor operations between tensors must happen with tensors of the same datatype**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Device\n",
    "The .device(), (which is cpu in our case), specifies the device where the tensor data is allocated. This determines where the computations for the given tensor will be performed.\n",
    "Pytorch supports the use of multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the device:\n",
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we can see that the device is *cuda*, which means the device is a cpu and the index=0 tells us that its the *first gpu that we have*.\n",
    "> If we specify cuda:1 or 2 or 3 etc. and we don't actually have 2 or more gpus we would get an error.  \n",
    "> **Tensor operations between tensors must happen between tensors *that exist on the same device*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layout\n",
    "Our layout is .strided\n",
    "It tells us how our tensors data is layed out in memory. For now we consider it as default and there is no need to change it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Take away from the tensor attributes\n",
    "\n",
    "As neural network programmers, we need to be aware of the following:\n",
    "\n",
    "    Tensors contain data of a uniform type (dtype).\n",
    "    Tensor computations between tensors depend on the dtype and the device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 data type is: torch.int64\n",
      "t2 data type is: torch.float32\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = torch.tensor([1.,2.,3.])\n",
    "print(f't1 data type is: {t1.dtype}')\n",
    "print(f't2 data type is: {t2.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Computation between datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Same process, with the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = t1.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Check the device the tensors are allocated on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 is on: cpu\n",
      "t2 is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "t1.device\n",
    "t2.device\n",
    "print(f't1 is on: {t1.device}')\n",
    "print(f't2 is on: {t2.device}') # It doesn't show index=0 probably because I have only one gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\Drs\\Programming\\Pytorch_Deeplizard\\pytorch_tensors.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Drs/Programming/Pytorch_Deeplizard/pytorch_tensors.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example computation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Drs/Programming/Pytorch_Deeplizard/pytorch_tensors.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m t1 \u001b[39m+\u001b[39;49m t2\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# Example computation\n",
    "t1 + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above error is quite self explanatory: Pytorch can't do computations between tensors that \"live\" on different devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ways of creating Tensors from data.\n",
    "These are the primary ways of creating tensor objects (instances of the torch.Tensor class), with data (array-like) in PyTorch:\n",
    "1. torch.Tensor(data)\n",
    "2. torch.tensor(data)\n",
    "3. torch.as_tensor(data)\n",
    "4. torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data using a numpy array\n",
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We will use the above array to create a tensor using the 4 different ways.\n",
    ">They all accept array-like structures like numpy arrays and give us instances of the pytorch tensor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The numpy array we created, has integers. The .Tensor() is a  class constructor  that returns floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The lowercase .tensor() is a function (factory function) that builds tensor objects.\n",
    "Here the datatype **maches the input data** of the numpy array we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. as_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(data) # Notice the output is the same as the .tensor factory function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. torch.from_numpy() gives the same outpus as 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The oddball here is the .Tensor() class constructor. All the others behave seemingly in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating tensors without data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***The identity tensor/matrix***.\n",
    "To call this function, we just specify the number of rows we want. (Ones down the diagonal and zeros everywhere else.)    \n",
    "\n",
    "**torch.eye(number of rows)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ***Zeros function***  \n",
    "When we call it we specify the length of each axis.\n",
    "\n",
    "**torch.zeros(rows, columns)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ***Ones function***  \n",
    "As above, except returns 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Randomized values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4955, 0.3439],\n",
       "        [0.5842, 0.4087]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Main takeaway:** We can either create tensors using pre-existing data, or we can do it using predefined functions for common data values like 0,1 or randoms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
